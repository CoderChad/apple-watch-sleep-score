# -*- coding: utf-8 -*-
"""sleepqualityassesmentsystem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Csdm-r0JPyQvh1PHxSKjVdXPnJoWp5N9
"""

import os
import numpy as np
import pandas as pd
from scipy import stats
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
import joblib
from typing import Dict, List, Tuple, Optional, Union
import datetime
import json
import logging

logger = logging.getLogger("sleep_quality")

class SleepQualityAssessor:
    """
    Processes Apple Watch sleep-session data to extract features,
    compute a sleep quality score (0–100), and generate insights.
    """

    # For backwards compatibility
    MIN_DATA_POINTS: int = 120
    # e.g. one HR sample every 30 seconds
    SAMPLING_INTERVAL_SEC: int = 30

    DEFAULT_WEIGHTS = {
        'heart_rate_pattern': 0.25,
        'hrv_quality':        0.20,
        'sleep_stage_balance':0.15,
        'oxygen_saturation':  0.15,
        'sleep_continuity':   0.15,
        'sleep_efficiency':   0.10
    }
    SCORE_RANGE: Tuple[int,int] = (0, 100)

    # Holds the last validation error message
    _last_validation_error: Optional[str] = None

    def __init__(self, user_id: str, model_path: Optional[str] = None):
        self.user_id = user_id
        self.model = None
        self.user_baselines: Dict[str, Union[float,str]] = {}
        self.scaler = MinMaxScaler()

        # storage dir for models & baselines
        self.storage_path = os.path.expanduser("~/.sleep_quality")
        os.makedirs(self.storage_path, exist_ok=True)

        # load existing model if provided
        if model_path:
            self._load_model(model_path)

    def _load_model(self, model_path: str) -> None:
        try:
            self.model = joblib.load(model_path)
            logger.info(f"Model loaded from {model_path}")
        except Exception as e:
            logger.error(f"Failed to load model: {e}")
            raise

    def _save_model(self, model_path: str) -> None:
        try:
            joblib.dump(self.model, model_path)
            logger.info(f"Model saved to {model_path}")
        except Exception as e:
            logger.error(f"Failed to save model: {e}")
            raise

    def _validate_input_data(self, sleep_data: Dict) -> bool:
        """
        Ensure sleep_data has all required fields and enough quality.
        Uses SAMPLING_INTERVAL_SEC to scale the minimum-point threshold.
        """
        required = ['heart_rate','hrv','spo2','wrist_temp',
                    'sleep_stages','start_time','end_time']
        for f in required:
            if f not in sleep_data:
                self._last_validation_error = f"Missing required field: {f}"
                logger.error(self._last_validation_error)
                return False

        # compute expected points from duration and sampling interval
        try:
            start = datetime.datetime.fromisoformat(sleep_data['start_time'])
            end   = datetime.datetime.fromisoformat(sleep_data['end_time'])
        except Exception as e:
            self._last_validation_error = f"Bad time format: {e}"
            logger.error(self._last_validation_error)
            return False

        total_secs = (end - start).total_seconds()
        expected = int(total_secs / self.SAMPLING_INTERVAL_SEC)
        # require at least 50% of expected
        hr_len = len(sleep_data['heart_rate'])
        if hr_len < expected * 0.5:
            self._last_validation_error = (
                f"Insufficient heart rate data points: got {hr_len}, "
                f"expected at least ~{int(expected*0.5)}"
            )
            logger.error(self._last_validation_error)
            return False

        # missing-value checks (<30% NaN)
        for k in ['heart_rate','hrv','spo2']:
            arr = np.array(sleep_data[k], dtype=float)
            missing = np.isnan(arr).mean()
            if missing > 0.3:
                self._last_validation_error = (
                    f"Too many missing values in {k}: {missing:.0%}"
                )
                logger.error(self._last_validation_error)
                return False

        # warn if very short or long
        hours = total_secs / 3600
        if hours < 1 or hours > 14:
            logger.warning(f"Unusual sleep duration: {hours:.2f}h")

        # all checks passed
        self._last_validation_error = None
        return True

    def extract_features(self, sleep_data: Dict) -> Dict:
        """
        After validation, compute all intermediate features needed for scoring.
        Raises ValueError(self._last_validation_error) on bad data.
        """
        if not self._validate_input_data(sleep_data):
            raise ValueError(self._last_validation_error or "Invalid input data")

        # Example: classify HR pattern
        hr_arr = np.array(sleep_data['heart_rate'], dtype=float)
        pattern_name, hr_score = self._classify_heart_rate_pattern(
            hr_arr, sleep_data['sleep_stages']
        )
        hrv_score = self._evaluate_hrv_quality(np.array(sleep_data['hrv'], dtype=float))
        stage_balance = self._evaluate_sleep_stage_balance(sleep_data['sleep_stages'])
        oxy_score = self._evaluate_oxygen_saturation(np.array(sleep_data['spo2'], dtype=float))
        cont_score = self._evaluate_sleep_continuity(
            hr_arr, sleep_data['sleep_stages']
        )

        # more features...
        total_sleep = sum(sleep_data['sleep_stages'][st]
                          for st in ['deep','rem','light'])
        efficiency = total_sleep / (total_sleep + sleep_data['sleep_stages']['awake'])

        features = {
            'heart_rate_pattern_name': pattern_name,
            'heart_rate_pattern':      hr_score,
            'hrv_quality':             hrv_score,
            'sleep_stage_balance':     stage_balance,
            'oxygen_saturation':       oxy_score,
            'sleep_continuity':        cont_score,
            'sleep_efficiency':        efficiency,
            'deep_sleep_ratio':        sleep_data['sleep_stages']['deep']/total_sleep,
            'rem_sleep_ratio':         sleep_data['sleep_stages']['rem']/total_sleep,
            'wrist_temp_delta':        None,  # compute if desired
            'date':                    sleep_data.get('date',
                                          datetime.datetime.now().date().isoformat())
        }
        return features

    def calculate_sleep_score(self,
                              features: Dict,
                              weights: Optional[Dict]=None) -> int:
        """Combine features with weights and normalize to 0–100."""
        if weights is None:
            weights = self.DEFAULT_WEIGHTS
        total = sum(features[f] * w
                    for f,w in weights.items()
                    if isinstance(features.get(f), (int,float)))
        score = int(max(self.SCORE_RANGE[0],
                        min(self.SCORE_RANGE[1],
                            total * 100)))
        return score

    def generate_insights(self, features: Dict, score: int) -> List[Dict]:
        """Produce user-facing tips based on feature values."""
        insights: List[Dict] = []
        # heart-rate pattern tips
        pn = features['heart_rate_pattern_name']
        if pn == "Hammock":
            insights.append({
                'area':'Heart Rate Pattern',
                'observation':'Optimal "Hammock" pattern—great recovery.',
                'recommendation':'Keep your evening routine consistent.'
            })
        elif pn == "Downhill":
            insights.append({
                'area':'Heart Rate Pattern',
                'observation':'Good "Downhill" pattern.',
                'recommendation':'Aim for a stable sleep schedule.'
            })
        # ... other pattern branches ...

        # stage balance
        if features['sleep_stage_balance'] < 0.6:
            insights.append({
                'area':'Sleep Stage Balance',
                'observation':'Imbalanced proportions of deep/REM sleep.',
                'recommendation':'Improve sleep hygiene: reduce caffeine, etc.'
            })

        # continuity
        if features['sleep_continuity'] < 0.6:
            insights.append({
                'area':'Sleep Continuity',
                'observation':'Fragmented sleep detected.',
                'recommendation':'Minimize noise/light and limit fluids at night.'
            })

        # oxygen
        if features['oxygen_saturation'] < 0.7:
            insights.append({
                'area':'Blood Oxygen',
                'observation':'Some desaturations noticed.',
                'recommendation':'Consider side-sleeping; consult provider if persists.'
            })

        # final praise if high score
        if score > 85:
            insights.append({
                'area':'Overall',
                'observation':'Excellent sleep quality!',
                'recommendation':'Maintain your current habits.'
            })

        return insights

    def analyze_sleep(self, sleep_data: Dict) -> Dict:
        """
        Run full pipeline: features → score → insights.
        Returns {'user_id', 'date', 'features', 'score', 'insights'} on success,
        or {'error', 'status':'error'} on failure.
        """
        try:
            feats = self.extract_features(sleep_data)
            sc   = self.calculate_sleep_score(feats)
            ins  = self.generate_insights(feats, sc)
            return {
                'user_id':  self.user_id,
                'date':     feats.get('date'),
                'features': feats,
                'score':    sc,
                'insights': ins,
                'status':   'ok'
            }
        except ValueError as e:
            msg = str(e)
            logger.error(f"Error analyzing sleep data: {msg}")
            return {'error': msg, 'status': 'error'}

    def train_model(self, training_data: List[Dict]) -> None:
        """
        Given historical nights + user ratings, fit a RandomForest to predict satisfaction.
        """
        X, y = [], []
        for entry in training_data:
            sd = entry.get('sleep_data')
            rt = entry.get('user_rating')
            if not sd or rt is None: continue
            feats = self.extract_features(sd)
            vec = [feats[k] for k in [
                'heart_rate_pattern','hrv_quality','sleep_stage_balance',
                'oxygen_saturation','sleep_continuity','sleep_efficiency',
                'deep_sleep_ratio','rem_sleep_ratio'
            ]]
            X.append(vec); y.append(rt)
        if len(X) < 5:
            logger.warning("Too little data to train model.")
            return
        X_arr = np.array(X); y_arr = np.array(y)
        X_scaled = self.scaler.fit_transform(X_arr)
        self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.model.fit(X_scaled, y_arr)
        # save for reuse
        path = os.path.join(self.storage_path, f"user_{self.user_id}_model.joblib")
        self._save_model(path)

    def predict_satisfaction(self, features: Dict) -> float:
        """
        Predict user rating (0–1) from a trained model, fallback to normalized score.
        """
        if not self.model:
            logger.warning("No trained model, using calculated score.")
            return self.calculate_sleep_score(features) / 100.0
        vec = [features[k] for k in [
            'heart_rate_pattern','hrv_quality','sleep_stage_balance',
            'oxygen_saturation','sleep_continuity','sleep_efficiency',
            'deep_sleep_ratio','rem_sleep_ratio'
        ]]
        arr = np.array([vec])
        arr_scaled = self.scaler.transform(arr)
        return float(self.model.predict(arr_scaled)[0])

